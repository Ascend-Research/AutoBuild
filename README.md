# Building Optimal Neural Architectures using Interpretable Knowledge
# [Qua<sup>2</sup>SeDiMo](https://github.com/Ascend-Research/Qua2SeDiMo) Branch

<p align="center">
    <a href="https://aaai.org/Conferences/AAAI-23/" alt="Conference">
        <img src="https://img.shields.io/badge/AAAI'25-blue" /></a>
    <a href="https://github.com/Ascend-Research/AIO-P/blob/master/LICENSE" alt="License">
        <img src="https://img.shields.io/badge/License-MIT-purple" /></a>
    <a href="https://www.python.org/" alt="Python">
        <img src="https://img.shields.io/badge/Python-3.10-yellow" /></a>
    <a href="https://pytorch.org/" alt="PyTorch">
        <img src="https://img.shields.io/badge/PyTorch-2.1-orange" /></a>
<p/>

Repository for the Qua<sup>2</sup>SeDiMo [AAAI-25] code branch of AutoBuild [CVPR'24]. This repository branch deals with training interpretable predictors and examining the quantifiable sensitivity insights. It relies on datasets of sampled quantization configurations from the main code repository. It then builds optimal quantization configurations using an interpretable GNN predictor.

**Setting up the environment**
This code uses a different virtual environment than the main code repo, primarily that it does not rely on Diffusers or any other packages related to images, but *does* rely on [pytorch-geometric](https://pytorch-geometric.readthedocs.io/en/latest/) and  [torchsort](https://github.com/teddykoker/torchsort).

```
conda create -n "autobuild" python=3.10
conda activate autobuild
conda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=11.8 -c pytorch -c nvidia
pip install torchsort-0.1.9+pt21cu118-cp310-cp310-linux_x86_64.whl  (Downloaded from https://github.com/teddykoker/torchsort/releases/tag/v0.1.9)
conda install pyg -c pyg
conda install -c conda-forge onnx
pip install numpy==1.26.4 pandas
```

You will also need to install [pytorchltr](https://github.com/rjagerman/pytorchltr). Trying to just use `pip` caused issues in our case. Instead, do the following:
```
pip install cython
git clone https://github.com/rjagerman/pytorchltr.git
cd pytorchltr
python setup.py install
```

## Setup Datasets
Make two new directories: `/cache/`. `/cache/` should be populated using content from the [Google Drive](https://drive.google.com/drive/folders/19gTl00BfDaQSQMlOC_aM5MMPo6grHC_1?usp=sharing).

## Running the predictor
We consider three hop-level losses: SRCC, LambdaRank (NDCG) and a hybrid loss that combines them both. Corresponding with this, we have three top-level predictor files: `train_predictor_fold_{srcc, ndcg, hybrid}.py`. Example usage:
```
python train_predictor_fold_ndcg.py -families alpha -tag "alpha_ndcg_code_submission" -target "-1*FID-GT-1k - avg_bits*150" > example_alpha_fid_bits.txt;
```

**Flags**
* `-families` is the denoiser neural network. Choose from {alpha, sigma, hunyuan, sdxl, sdv15, dit}
* `-target` is the target equation to optimize, e.g., `"-1*FID-GT-1k - avg_bits*150"` in the paper. Default is `"FID-GT-1k*-1"`. Should be an arithmetric equation involving dataset keys from `/cache/`, namely `FID-GT-1k`, `avg_bits` and `bops`. Please see `/ge_utils/label_eq.py` for more details on how `-target` syntax is processed.


This script uses joblib to the `K=5` fold splits simultaneously. We strongly recommend piping output to a text file as shown in the example. The script will report SRCC and/or NDCG@10 for each fold. When each fold is complete, it will then call `label_units_sdm_fold.py` twice to perform the subgraph labeling, once for the node-level optimization, and again for the subgraph-level optimization. These are the subgraph scores, stored in `units/`. We provide several examples for the node and subgraph optimization already (subgraph-level optimization files are large, so there's only a few). You can use ipython and pickle to open the file and enumerate the subgraphs to look at how they are setup and their scores. 

Additionally, `label_units_sdm_fold.py` calls `convert_sdm_unit_to_scheme` to generate the optimal quantization configuration and store it in `quant_configs/`. These can then be used with the main Qua<sup>2</sup>SeDiMo code repository.

## Analyzing Quantization Sensitivity Insights and Generating Plots
We now introduce the scripts used to generate the quantization sensitivity insight plots in the paper. 

There are two types of quantization sensitivity scripts: `box` plots and `bar` plots:
* `box` plot examples include Figures 7, 12 and 13 in the paper. These plots are generated by looking at the distribution of *all* subgraph scores a predictor can produce for a given denoiser neural network. 
* `bar` plots analyze *individual* quantization configurations. Examples include Figs 8 and 15. 

### Box Plots
Box plots look at a given block/operation in the denoiser, e.g., *t-Emb*, *c-Emb*, *Out Proj*, *SA/CA-Q/K/V-Out* or a specific Transformer block/layer index and look at the distribution of quantization configuration scores for all possible quantization methods and bit precisions for that given module (e.g., self-attention, configs = 6<sup>#W</sup>) or operation (e.g., SA-Q, configs = 6). For each block/op, we compute the box plot of quantization sensitivity scores for it. If the sensitivity score range has high range, or several high-value outliers, then there are specific quantization configurations for that block/op that are important to achieving the objective the original predictor is trained on. For example, take the PixArt-Sigma results in Fig. 7: Self-Attention has a lot of outliers, indicating that this block module possess a high degree of importance. 

Box plot scripts takes subgraph score files from the `/units/` folder (examples downloadable from the [Google Drive](https://drive.google.com/drive/folders/19gTl00BfDaQSQMlOC_aM5MMPo6grHC_1?usp=sharing)). 
We provide three box plot scripts: `graph_blk_box.py`, `graph_op_box.py` and `node_op_box.py`:  
* `graph_blk_box.py` looks at the block *indices*, e.g., DiT-XL/2 and PixArt DiTs have 28 Transformer blocks, while Hunyuan has 40 and computes the score distributions per block index. Example: Fig. 13 in paper. Being a `graph` script, you need to provide it with subgraph-level scores, e.g., (sgs_labeled.pkl) files from `/units/`. Example:
```
python graph_blk_box.py -unit units/dit_35_sgs_labeled.pkl -title "example_35_idx"
```

* `graph_op_box.py` and `node_op_box.py` look at block/operation *types*, e.g., the entire self-attention mechanism (graph, Fig. 7 and Fig. 12 for DiT 3.5-bit) or the SA-Q layer (node, most of Fig. 12). Example usage:
```
python graph_op_box.py -unit units/hunyuan_365_sgs_labeled.pkl -title "example_365_blk"
``` 


### Bar Plots
Bar plots look at the distribution of quantization method and bit precision for a given operation (e.g., *SA/CA-Q/K/V*) across all instances of that operation. Take the PixArt-Alpha 3.4-bit quantization configuration in Fig 8 for example. PixArt-Alpha contains 28 Transformer blocks, so 28 self-attention modules, each containing one *query* (SA-Q) and one *key* (SA-K) weight layer (among others). We see that in this case, the SA-Q bar plot has more dark colors (corresponding to 3-bit quantization) than SA-K, indicating that the query self-attention layer is *more readily* quantized to 3-bit precision than the key self-attention layer on average.

Bar plot scripts takes subgraph score files from the `/units/` folder (examples downloadable from the [Google Drive](https://drive.google.com/drive/folders/19gTl00BfDaQSQMlOC_aM5MMPo6grHC_1?usp=sharing)). We provide two bar plot scripts: `graph_op_bar.py` and `node_op_bar.py` corresponding directly to whether a quantization configuration was built using block-level (sgs_labeled.pkl), or operation-level (nodes_labeled.pkl) optimization (see Figs. 4, 9 and 10), respectively. Example usage:

```
python graph_op_bar.py -unit units/sigma_39_sgs_labeled.pkl -title "example_sigma_39_bar"
python node_op_bar.py -unit units/alpha_40_nodes_labeled.pkl -title "example_alpha_40_bar"
```
